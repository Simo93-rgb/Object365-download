{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "d4090f78",
   "metadata": {},
   "source": [
    "# Objects365 Dataset Download and Processing\n",
    "This notebook downloads and processes the Objects365 dataset, generating annotations in YOLO format."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9247375c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "import tarfile\n",
    "import numpy as np\n",
    "from pathlib import Path\n",
    "from tqdm import tqdm\n",
    "import requests\n",
    "from typing import List, Union, Tuple, Optional\n",
    "from concurrent.futures import ThreadPoolExecutor\n",
    "from zipfile import ZipFile, is_zipfile\n",
    "from itertools import repeat\n",
    "from multiprocessing.pool import ThreadPool\n",
    "\n",
    "# Verify that pycocotools is installed\n",
    "try:\n",
    "    from pycocotools.coco import COCO\n",
    "except ImportError:\n",
    "    print(\"Installation of pycocotools required. Run: pip install pycocotools>=2.0\")\n",
    "    sys.exit(1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "869e8459",
   "metadata": {},
   "source": [
    "## Support Functions\n",
    "These functions handle downloading, extraction, and conversion of annotations."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1763e709",
   "metadata": {},
   "outputs": [],
   "source": [
    "def download_with_resume(url: str, dest: Union[str, Path], retry: int = 3) -> None:\n",
    "    \"\"\"\n",
    "    Downloads a file from a given URL with support for resuming partial downloads.\n",
    "    \"\"\"\n",
    "    headers = {}\n",
    "    if os.path.exists(dest):\n",
    "        headers['Range'] = f\"bytes={os.path.getsize(dest)}-\"\n",
    "    with requests.get(url, headers=headers, stream=True) as r:\n",
    "        total_size = int(r.headers.get('content-length', 0)) + os.path.getsize(dest)\n",
    "        if r.status_code == 416:\n",
    "            print(f\"{dest} is already fully downloaded.\")\n",
    "            return\n",
    "        elif r.status_code not in (200, 206):\n",
    "            raise Exception(f\"Failed to download {url}: {r.status_code}\")\n",
    "        with open(dest, \"ab\") as f, tqdm(\n",
    "            desc=f\"Downloading {Path(dest).name}\",\n",
    "            total=total_size,\n",
    "            unit=\"B\",\n",
    "            unit_scale=True,\n",
    "            unit_divisor=1024,\n",
    "            initial=os.path.getsize(dest),\n",
    "        ) as bar:\n",
    "            for chunk in r.iter_content(chunk_size=65536):\n",
    "                if chunk:\n",
    "                    f.write(chunk)\n",
    "                    bar.update(len(chunk))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e30b5135",
   "metadata": {},
   "outputs": [],
   "source": [
    "def xyxy2xywhn(xyxy: np.ndarray, w: Union[int, float] = 640, h: Union[int, float] = 640, clip: bool = False, eps: float = 0.0) -> np.ndarray:\n",
    "    \"\"\"\n",
    "    Converts bounding box coordinates from (x_min, y_min, x_max, y_max) format \n",
    "    to normalized (x_center, y_center, width, height) format.\n",
    "    \"\"\"\n",
    "    if clip:\n",
    "        xyxy[:, 0] = np.maximum(0, np.minimum(xyxy[:, 0], w - eps))\n",
    "        xyxy[:, 1] = np.maximum(0, np.minimum(xyxy[:, 1], h - eps))\n",
    "        xyxy[:, 2] = np.maximum(0, np.minimum(xyxy[:, 2], w - eps))\n",
    "        xyxy[:, 3] = np.maximum(0, np.minimum(xyxy[:, 3], h - eps))\n",
    "    \n",
    "    y = xyxy.copy()\n",
    "    y[:, 0] = ((xyxy[:, 0] + xyxy[:, 2]) / 2) / w  # x center\n",
    "    y[:, 1] = ((xyxy[:, 1] + xyxy[:, 3]) / 2) / h  # y center\n",
    "    y[:, 2] = (xyxy[:, 2] - xyxy[:, 0]) / w        # width\n",
    "    y[:, 3] = (xyxy[:, 3] - xyxy[:, 1]) / h        # height\n",
    "    return y"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "acb86d63",
   "metadata": {},
   "source": [
    "## Directory Setup\n",
    "Set the base directories for the dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1bea43e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "threads = 16  # Number of threads for downloading\n",
    "base_dir = Path(\"/mnt/e/object365\")\n",
    "base_dir.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "# Create directories\n",
    "for p in [\"images\", \"labels\"]:\n",
    "    for q in [\"train\", \"val\"]:\n",
    "        (base_dir / p / q).mkdir(parents=True, exist_ok=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c24d8515",
   "metadata": {},
   "source": [
    "## Download Annotations and Images\n",
    "Download the necessary files for the Objects365 dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "23cc1630",
   "metadata": {},
   "outputs": [],
   "source": [
    "for split, patches in [(\"train\", 50 + 1), (\"val\", 43 + 1)]:\n",
    "    print(f\"Processing {split} in {patches} patches ...\")\n",
    "    images, labels = base_dir / \"images\" / split, base_dir / \"labels\" / split\n",
    "\n",
    "    # Base URL\n",
    "    url = f\"https://dorc.ks3-cn-beijing.ksyun.com/data-set/2020Objects365%E6%95%B0%E6%8D%AE%E9%9B%86/{split}/\"\n",
    "\n",
    "    # Download annotations\n",
    "    if split == \"train\":\n",
    "        download_with_resume(f\"{url}zhiyuan_objv2_{split}.tar.gz\", base_dir / f\"zhiyuan_objv2_{split}.tar.gz\")\n",
    "    elif split == \"val\":\n",
    "        download_with_resume(f\"{url}zhiyuan_objv2_{split}.json\", base_dir / f\"zhiyuan_objv2_{split}.json\")\n",
    "\n",
    "    # Download images\n",
    "    if split == \"train\":\n",
    "        print(f\"Downloading training images ({patches} patches)...\")\n",
    "        for i in range(patches):\n",
    "            download_with_resume(f\"{url}patch{i}.tar.gz\", images / f\"patch{i}.tar.gz\")\n",
    "    elif split == \"val\":\n",
    "        print(\"Downloading validation images v1...\")\n",
    "        for i in range(15 + 1):\n",
    "            download_with_resume(f\"{url}images/v1/patch{i}.tar.gz\", images / f\"v1_patch{i}.tar.gz\")\n",
    "        print(\"Downloading validation images v2...\")\n",
    "        for i in range(16, patches):\n",
    "            download_with_resume(f\"{url}images/v2/patch{i}.tar.gz\", images / f\"v2_patch{i}.tar.gz\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5f526119",
   "metadata": {},
   "source": [
    "## Annotation Processing\n",
    "Convert annotations to YOLO format."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "167f106e",
   "metadata": {},
   "outputs": [],
   "source": [
    "for split in [\"train\", \"val\"]:\n",
    "    annotations_path = base_dir / f\"zhiyuan_objv2_{split}.json\"\n",
    "    if annotations_path.exists():\n",
    "        coco = COCO(annotations_path)\n",
    "        names = [x[\"name\"] for x in coco.loadCats(coco.getCatIds())]\n",
    "\n",
    "        for cid, cat in enumerate(names):\n",
    "            catIds = coco.getCatIds(catNms=[cat])\n",
    "            imgIds = coco.getImgIds(catIds=catIds)\n",
    "\n",
    "            for im in tqdm(coco.loadImgs(imgIds), desc=f\"Class {cid + 1}/{len(names)} {cat}\"):\n",
    "                width, height = im[\"width\"], im[\"height\"]\n",
    "                path = Path(im[\"file_name\"])\n",
    "\n",
    "                try:\n",
    "                    label_file = labels / path.with_suffix(\".txt\").name\n",
    "                    with open(label_file, \"a\", encoding=\"utf-8\") as file:\n",
    "                        annIds = coco.getAnnIds(imgIds=im[\"id\"], catIds=catIds, iscrowd=None)\n",
    "                        for a in coco.loadAnns(annIds):\n",
    "                            x, y, w, h = a[\"bbox\"]\n",
    "                            xyxy = np.array([[x, y, x + w, y + h]])\n",
    "                            x, y, w, h = xyxy2xywhn(xyxy, w=width, h=height, clip=True)[0]\n",
    "                            file.write(f\"{cid} {x:.5f} {y:.5f} {w:.5f} {h:.5f}\\n\")\n",
    "                except Exception as e:\n",
    "                    print(f\"Error processing image {path}: {e}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
